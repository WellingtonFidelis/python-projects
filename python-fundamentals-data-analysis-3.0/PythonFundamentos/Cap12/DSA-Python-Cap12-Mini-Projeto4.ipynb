{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGC2SL0YXohk"
   },
   "source": [
    "# <font color='blue'>Data Science Academy - Python Fundamentos - Capítulo 12</font>\n",
    "\n",
    "## Download: http://github.com/dsacademybr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Projeto 4 - Inteligência Artificial na Agricultura "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATENÇÃO**\n",
    "\n",
    "Este Mini-Projeto é um bônus com nível intermediário/avançado e o que apresentaremos aqui é apenas uma demonstração. Os conceitos necessários para executar este Mini-Projeto são estudados em detalhes na <a href=\"https://www.datascienceacademy.com.br/bundle/formacao-inteligencia-artificial\">Formação Inteligência Artificial</a> e <a href=\"https://www.datascienceacademy.com.br/bundle/formacao-inteligencia-artificial-aplicada-a-medicina\">Formação Inteligência Artificial Aplicada à Medicina</a> aqui na DSA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/mini-projeto4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do Problema\n",
    "\n",
    "Acesse o manual em pdf no Capítulo 12 do curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonte de Dados\n",
    "\n",
    "Acesse o manual em pdf no Capítulo 12 do curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando e Carregando Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.7\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o TensorFlow\n",
    "#!pip install -q tensorflow==2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3kqz7dCkX2FP"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomRotation\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomZoom\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed para reprodutibilidade\n",
    "tf.random.set_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_SAZtH4Xsfl"
   },
   "source": [
    "## Carregando os Dados (Imagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dG9pilkrZfBI",
    "outputId": "38eeca10-21f4-4f3d-fa15-5b08529db3e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\welli\\Documents\\Projects\\python-projects\\python-fundamentals-data-analysis-3.0\\PythonFundamentos\\Cap12\n"
     ]
    }
   ],
   "source": [
    "# Diretório atual\n",
    "diretorio_atual = Path.cwd()\n",
    "print(diretorio_atual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para os dados de treino\n",
    "caminho_dados_treino = Path(\"fruits-360/Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qVMjTIgRYBnz"
   },
   "outputs": [],
   "source": [
    "# Caminho para os dados de teste\n",
    "caminho_dados_teste = Path(\"fruits-360/Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listando o conteúdo da pasta\n",
    "imagens_treino = list(caminho_dados_treino.glob(\"*/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('fruits-360/Training/Apple Crimson Snow/r_90_100.jpg'),\n",
       " WindowsPath('fruits-360/Training/Apple Crimson Snow/r_91_100.jpg'),\n",
       " WindowsPath('fruits-360/Training/Apple Crimson Snow/r_92_100.jpg'),\n",
       " WindowsPath('fruits-360/Training/Apple Crimson Snow/r_93_100.jpg'),\n",
       " WindowsPath('fruits-360/Training/Apple Crimson Snow/r_94_100.jpg'),\n",
       " WindowsPath('fruits-360/Training/Apple Crimson Snow/r_95_100.jpg'),\n",
       " WindowsPath('fruits-360/Training/Apple Crimson Snow/r_96_100.jpg'),\n",
       " WindowsPath('fruits-360/Training/Apple Crimson Snow/r_97_100.jpg'),\n",
       " WindowsPath('fruits-360/Training/Apple Crimson Snow/r_98_100.jpg'),\n",
       " WindowsPath('fruits-360/Training/Apple Crimson Snow/r_99_100.jpg'),\n",
       " WindowsPath('fruits-360/Training/Apple Crimson Snow/r_9_100.jpg')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza uma amostra da lista\n",
    "imagens_treino[925:936]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0qRlLoazYBlf",
    "outputId": "7b4ba93f-5697-4b8f-a758-6ec22bcf476b"
   },
   "outputs": [],
   "source": [
    "# Expressão lambda que extrai apenas o valor com o caminho de cada imagem\n",
    "imagens_treino = list(map(lambda x: str(x), imagens_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_90_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_91_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_92_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_93_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_94_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_95_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_96_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_97_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_98_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_99_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_9_100.jpg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza uma amostra da lista\n",
    "imagens_treino[925:936]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67692"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de imagens de treino\n",
    "len(imagens_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJrBa7Bwd0TY"
   },
   "source": [
    "## Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que obtém o label de cada imagem\n",
    "def extrai_label(caminho_imagem):\n",
    "    return caminho_imagem.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função\n",
    "imagens_treino_labels = list(map(lambda x: extrai_label(x), imagens_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0DPLuAtYBjM",
    "outputId": "0b90d198-9add-4089-ec22-b4d262a2d2d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_238_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_239_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_240_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_241_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_242_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Apple Crimson Snow\\\\r_243_100.jpg']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza uma amostra\n",
    "imagens_treino_labels[840:846]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Label encoding (convertendo string para valor numérico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_yBYn-_YBgk",
    "outputId": "e840ceb0-0c48-4f18-8c08-f23ca6f83d4e"
   },
   "outputs": [],
   "source": [
    "# Cria o objeto\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o fit_transform\n",
    "imagens_treino_labels = encoder.fit_transform(imagens_treino_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([840, 841, 842, 843, 844, 845], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza uma amostra\n",
    "imagens_treino_labels[840:846]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDlzQbHVYBdu",
    "outputId": "40aeab7c-8416-4055-c70a-09f9edb4a993"
   },
   "outputs": [],
   "source": [
    "# Aplicamos One-Hot-Encoding nos labels\n",
    "imagens_treino_labels = tf.keras.utils.to_categorical(imagens_treino_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza uma amostra\n",
    "imagens_treino_labels[840:846]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ys0X8AzrYBaO"
   },
   "outputs": [],
   "source": [
    "# Dividimos os dados de treino em duas amostras, treino e validação\n",
    "X_treino, X_valid, y_treino, y_valid = train_test_split(imagens_treino, imagens_treino_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjLMt5MgYBXh",
    "outputId": "cac15436-5e08-4d9b-f6ab-8986fe6c52ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fruits-360\\\\Training\\\\Pepper Orange\\\\r2_136_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Tomato Heart\\\\r2_175_100.jpg',\n",
       " 'fruits-360\\\\Training\\\\Cherry Wax Red\\\\r_16_100.jpg']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treino[15:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treino[15:18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRgDhAT2eogt"
   },
   "source": [
    "## Dataset Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionamento de todas as imagens para 224 x 224\n",
    "img_size = 224\n",
    "resize = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.Resizing(img_size, img_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "mv_3vO6OecLJ"
   },
   "outputs": [],
   "source": [
    "# Cria o objeto para dataset augmentation\n",
    "data_augmentation = tf.keras.Sequential([RandomFlip(\"horizontal\"),\n",
    "                                         RandomRotation(0.2),\n",
    "                                         RandomZoom(height_factor = (-0.3,-0.2)) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnBBDWm4xL6v"
   },
   "source": [
    "## Preparando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmnetros\n",
    "batch_size = 32\n",
    "autotune = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar e transformar as imagens\n",
    "def carrega_transforma(image, label):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image, channels = 3)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XTXr9NbJecGo"
   },
   "outputs": [],
   "source": [
    "# Função para preparar os dados noo formato do TensorFlow\n",
    "def prepara_dataset(path, labels, train = True):\n",
    "\n",
    "    # Prepara os dados\n",
    "    image_paths = tf.convert_to_tensor(path)\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "    dataset = dataset.map(lambda image, label: carrega_transforma(image, label)) \n",
    "    dataset = dataset.map(lambda image, label: (resize(image), label), num_parallel_calls = autotune)\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Se train = True aplica dataset augmentation\n",
    "    if train:\n",
    "        dataset = dataset.map(lambda image, label: (data_augmentation(image), label), num_parallel_calls = autotune)\n",
    "  \n",
    "    # Se train = False repete sobre o dataset e retorna\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhNsLlDfecDx",
    "outputId": "f8bc3345-772f-4b05-bc2d-f9c1a06645c0"
   },
   "outputs": [],
   "source": [
    "# Cria o dataset de treino\n",
    "dataset_treino = prepara_dataset(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQaXtLxNuKMt",
    "outputId": "a3de81e3-d3a6-4e0c-febc-f19f9145b91b"
   },
   "outputs": [],
   "source": [
    "# Shape\n",
    "imagem, label = next(iter(dataset_treino))\n",
    "print(imagem.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "6ON1ikVHvl4V",
    "outputId": "56de83c8-8abb-48fd-8eb0-543400e7beab"
   },
   "outputs": [],
   "source": [
    "# Vamos visualizar uma imagem e um label\n",
    "print(encoder.inverse_transform(np.argmax(label, axis = 1))[0])\n",
    "plt.imshow((imagem[0].numpy()/255).reshape(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cQb4CS9wLQy",
    "outputId": "2e53fc2b-a1e0-4991-d2d5-512a7b6e4f93"
   },
   "outputs": [],
   "source": [
    "# Cria o dataset de validação\n",
    "dataset_valid = prepara_dataset(X_valid, y_valid, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBmTkHG9wLOH",
    "outputId": "bd018759-fa0e-44f0-f433-3a4cfa5566a6"
   },
   "outputs": [],
   "source": [
    "# Shape\n",
    "imagem, label = next(iter(dataset_valid))\n",
    "print(imagem.shape) \n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvmCKh6WxG4Z"
   },
   "source": [
    "## Construção do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando um modelo pré-treinado\n",
    "modelo_pre = EfficientNetB3(input_shape = (224,224,3), include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WM_GgNEYwLHV",
    "outputId": "9e0073be-ee36-4c82-ad71-02dce54d79c6"
   },
   "outputs": [],
   "source": [
    "# Adicionando nossas próprias camadas ao modelo_pre\n",
    "modelo = tf.keras.Sequential([modelo_pre,\n",
    "                              tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                              tf.keras.layers.Dense(131, activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário do modelo\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros\n",
    "lr = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "ep = 1e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugXp1k-pyyCK"
   },
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "modelo.compile(optimizer = Adam(learning_rate = lr, \n",
    "                                beta_1 = beta1, \n",
    "                                beta_2 = beta2, \n",
    "                                epsilon = ep),\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy', Precision(name = 'precision'), Recall(name = 'recall')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vamos treinar o modelo por apenas uma época e verificar as métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Se você treinar o modelo em um computador sem GPU o tempo de treinamento será bastante alto, provavelmente de muitas horas. Pratique a paciência e aguarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOVsDMcGyx_n",
    "outputId": "371b3aa2-75db-4394-98de-5cb9c76c04c0"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = modelo.fit(dataset_treino,\n",
    "                     steps_per_epoch = len(X_treino)//batch_size,\n",
    "                     epochs = 1,\n",
    "                     validation_data = dataset_valid,\n",
    "                     validation_steps = len(y_treino)//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vamos treinar o modelo por mais 6 épocas a fim de melhorar a performance e aplicar algumas técnicas para evitar overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ll72F5N2wLEs"
   },
   "outputs": [],
   "source": [
    "# Não precisamos mais do modelo_pre\n",
    "modelo.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KF5njqwAwF2Y"
   },
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"modelo/melhor_modelo.h5\", \n",
    "                                                verbose = 1, \n",
    "                                                save_best = True, \n",
    "                                                save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stop\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience = 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXQoAuOI4Iz_"
   },
   "outputs": [],
   "source": [
    "# Sumário\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbEzuklh53pV"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = modelo.fit(dataset_treino,\n",
    "                     steps_per_epoch = len(X_treino)//batch_size,\n",
    "                     epochs = 6,\n",
    "                     validation_data = dataset_valid,\n",
    "                     validation_steps = len(y_treino)//batch_size,\n",
    "                     callbacks = [checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZrQymGvS7xT"
   },
   "source": [
    "## Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para carregar os pesos, precisamos descongelar as camadas\n",
    "modelo.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-N9Kn9Z853kn"
   },
   "outputs": [],
   "source": [
    "# Carrega os pesos do ponto de verificação e reavalie\n",
    "modelo.load_weights(\"modelo/melhor_modelo.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Carregamos os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUXUnLyPUA9i"
   },
   "outputs": [],
   "source": [
    "# Carregando e preparando os dados de teste\n",
    "camninho_imagens_teste = list(caminho_dados_teste.glob(\"*/*\"))\n",
    "imagens_teste = list(map(lambda x: str(x), camninho_imagens_teste))\n",
    "imagens_teste_labels = list(map(lambda x: extrai_label(x), imagens_teste))\n",
    "imagens_teste_labels = encoder.fit_transform(imagens_teste_labels)\n",
    "imagens_teste_labels = tf.keras.utils.to_categorical(imagens_teste_labels)\n",
    "test_image_paths = tf.convert_to_tensor(imagens_teste)\n",
    "test_image_labels = tf.convert_to_tensor(imagens_teste_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para decode das imagens\n",
    "def decode_imagens(image, label):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image, channels = 3)\n",
    "    image = tf.image.resize(image, [224,224], method = \"bilinear\")\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lqb0-TyXVQO8"
   },
   "outputs": [],
   "source": [
    "# Cria o dataset de teste\n",
    "dataset_teste = (tf.data.Dataset\n",
    "                 .from_tensor_slices((imagens_teste, imagens_teste_labels))\n",
    "                 .map(decode_imagens)\n",
    "                 .batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ab0HnioWKlk"
   },
   "outputs": [],
   "source": [
    "# Shape\n",
    "imagem, label = next(iter(dataset_teste))\n",
    "print(imagem.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvJecRwKXaLd"
   },
   "outputs": [],
   "source": [
    "# Visualiza uma imagem de teste\n",
    "print(encoder.inverse_transform(np.argmax(label, axis = 1))[0])\n",
    "plt.imshow((imagem[0].numpy()/255).reshape(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsHWI8QqhMcP"
   },
   "outputs": [],
   "source": [
    "# Avalia o modelo\n",
    "loss, acc, prec, rec = modelo.evaluate(dataset_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8d9ZW9zAhMWQ"
   },
   "outputs": [],
   "source": [
    "print(\"Acurácia: \", acc)\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeWyMW3mhSi8"
   },
   "source": [
    "## Previsões com o Modelo Treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar uma nova imagem\n",
    "def carrega_nova_imagem(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_jpeg(image, channels = 3)\n",
    "    image = tf.image.resize(image, [224,224], method = \"bilinear\")\n",
    "    plt.imshow(image.numpy()/255)\n",
    "    image = tf.expand_dims(image, 0) \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJ-CE8cFhMNK"
   },
   "outputs": [],
   "source": [
    "# Função para fazer previsões\n",
    "def faz_previsao(image_path, model, enc):\n",
    "    image = carrega_nova_imagem(image_path)\n",
    "    prediction = model.predict(image)\n",
    "    pred = np.argmax(prediction, axis = 1) \n",
    "    return enc.inverse_transform(pred)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUSKHefEhYXL"
   },
   "outputs": [],
   "source": [
    "# Previsão\n",
    "faz_previsao(\"imagens/imagem1.jpg\", modelo, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão\n",
    "faz_previsao(\"imagens/imagem2.jpg\", modelo, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão\n",
    "faz_previsao(\"imagens/imagem3.jpg\", modelo, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão\n",
    "faz_previsao(\"imagens/imagem4.jpg\", modelo, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão\n",
    "faz_previsao(\"imagens/imagem5.jpg\", modelo, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fruit_Identification_System_EfficientNetB3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
